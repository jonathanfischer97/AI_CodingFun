{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "# import deeplake \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(os.getcwd()+'/keys.env')\n",
    "activeloop_token = os.getenv('ACTIVELOOP_TOKEN')\n",
    "deeplake_username = os.getenv('DEEPLAKE_USERNAME')\n",
    "openai.api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "pdfdirname = os.getcwd()+'/../LangChainQueryTexts/ThesisPapers'\n",
    "pdfdirname = os.path.abspath(pdfdirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_docs(root_dir):\n",
    "    docs = []\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        for file in filenames:\n",
    "            print(file)\n",
    "            try:\n",
    "                loader = PyPDFLoader(os.path.join(\n",
    "                    dirpath, file))\n",
    "                docs.extend(loader.load_and_split())\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "    return docs\n",
    "\n",
    "\n",
    "def split_docs(docs):\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    return text_splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "def main(root_dir, deep_lake_path):\n",
    "    docs = load_docs(root_dir)\n",
    "    texts = split_docs(docs)\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    \n",
    "    db = DeepLake(dataset_path=deep_lake_path, embedding_function=embeddings)\n",
    "    \n",
    "    db.add_documents(texts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, split, and embed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfAssemblyOscillations.pdf\n",
      "Osman.pdf\n",
      "Sensitivity_analysis_of_autonomous_oscillations_ap.pdf\n",
      "DesignPrinciplesOscillators.pdf\n",
      "TunableOscillator.pdf\n",
      "GeneticAlgorithm.pdf\n"
     ]
    }
   ],
   "source": [
    "docs = load_docs(pdfdirname)\n",
    "texts = split_docs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<class 'openai.api_resources.embedding.Embedding'>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version='2022-12-01', openai_api_base=None, openai_api_type=None, embedding_ctx_length=8191, openai_api_key=None, openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Chroma vectorstore for pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "doc_retriever = Chroma.from_documents(texts, embeddings).as_retriever() #initialize vectorstore into retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "compressor = LLMChainExtractor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name=\"gpt-4\", streaming=True, callbacks=[StreamingStdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=chat, chain_type=\"stuff\", retriever=doc_retriever, return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membrane localization affects biochemical kinetics by influencing the time-scales of complexation and assembly of proteins. Protein-lipid affinities (KaPM) are critical in controlling the overall time-scales of complexation, even driving slowdowns in speeds relative to solution binding. Changes in diffusion from solution to the membrane, which are about 100 times slower, affect the magnitude of association and dissociation rates. However, the influence of diffusion on the reaction rates is rarely a dominant factor in physiological rate regimes, indicating that it is the binding strengths rather than slow 2D diffusion that determine assembly speeds. Membrane localization can also increase the sensitivity of complex formation to localization, acting as a trigger for assembly."
     ]
    }
   ],
   "source": [
    "query = \"How does membrane localization effect biochemical kinetics?\"\n",
    "result = qa({\"query\": query})\n",
    "# qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory=ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_qa = ConversationalRetrievalChain.from_llm(chat, doc_retriever,verbose=True, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing some input keys: {'chat_history', 'question'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m convo_qa\u001b[39m.\u001b[39mrun(\u001b[39minput\u001b[39m\u001b[39m=\u001b[39mquery)\n",
      "File \u001b[0;32m~/miniforge3/envs/ai2/lib/python3.11/site-packages/langchain/chains/base.py:239\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(args[\u001b[39m0\u001b[39m], callbacks\u001b[39m=\u001b[39mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m--> 239\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[1;32m    241\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`run` supported with either positional arguments or keyword arguments\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m but not both. Got args: \u001b[39m\u001b[39m{\u001b[39;00margs\u001b[39m}\u001b[39;00m\u001b[39m and kwargs: \u001b[39m\u001b[39m{\u001b[39;00mkwargs\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/ai2/lib/python3.11/site-packages/langchain/chains/base.py:123\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m    107\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    108\u001b[0m     inputs: Union[Dict[\u001b[39mstr\u001b[39m, Any], Any],\n\u001b[1;32m    109\u001b[0m     return_only_outputs: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    110\u001b[0m     callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    111\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[1;32m    112\u001b[0m     \u001b[39m\"\"\"Run the logic of this chain and add to output if desired.\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \n\u001b[1;32m    114\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m \n\u001b[1;32m    122\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_inputs(inputs)\n\u001b[1;32m    124\u001b[0m     callback_manager \u001b[39m=\u001b[39m CallbackManager\u001b[39m.\u001b[39mconfigure(\n\u001b[1;32m    125\u001b[0m         callbacks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose\n\u001b[1;32m    126\u001b[0m     )\n\u001b[1;32m    127\u001b[0m     new_arg_supported \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/ai2/lib/python3.11/site-packages/langchain/chains/base.py:216\u001b[0m, in \u001b[0;36mChain.prep_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     external_context \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory\u001b[39m.\u001b[39mload_memory_variables(inputs)\n\u001b[1;32m    215\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mexternal_context)\n\u001b[0;32m--> 216\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    217\u001b[0m \u001b[39mreturn\u001b[39;00m inputs\n",
      "File \u001b[0;32m~/miniforge3/envs/ai2/lib/python3.11/site-packages/langchain/chains/base.py:83\u001b[0m, in \u001b[0;36mChain._validate_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     81\u001b[0m missing_keys \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_keys)\u001b[39m.\u001b[39mdifference(inputs)\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m missing_keys:\n\u001b[0;32m---> 83\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing some input keys: \u001b[39m\u001b[39m{\u001b[39;00mmissing_keys\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Missing some input keys: {'chat_history', 'question'}"
     ]
    }
   ],
   "source": [
    "convo_qa.run(input=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
