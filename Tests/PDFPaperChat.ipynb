{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "# import deeplake \n",
    "from dotenv import load_dotenv\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(os.getcwd()+'/.env.AIKEYS')\n",
    "activeloop_token = os.getenv('ACTIVELOOP_TOKEN')\n",
    "deeplake_username = os.getenv('DEEPLAKE_USERNAME')\n",
    "openai.api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "pdfdirname = os.getcwd()+'/LangChainQueryTexts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_docs(root_dir):\n",
    "    docs = []\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        for file in filenames:\n",
    "            print(file)\n",
    "            try:\n",
    "                loader = PyPDFLoader(os.path.join(\n",
    "                    dirpath, file))\n",
    "                docs.extend(loader.load_and_split())\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "    return docs\n",
    "\n",
    "\n",
    "def split_docs(docs):\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    return text_splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "def main(root_dir, deep_lake_path):\n",
    "    docs = load_docs(root_dir)\n",
    "    texts = split_docs(docs)\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    \n",
    "    db = DeepLake(dataset_path=deep_lake_path, embedding_function=embeddings)\n",
    "    \n",
    "    db.add_documents(texts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, split, and embed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<class 'openai.api_resources.embedding.Embedding'>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version='2022-12-01', openai_api_base=None, openai_api_type=None, embedding_ctx_length=8191, openai_api_key=None, openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = load_docs(pdfdirname)\n",
    "texts = split_docs(docs)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not import chromadb python package. Please install it with `pip install chromadb`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.11/site-packages/langchain/vectorstores/chroma.py:68\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 68\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chromadb'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m docsearch \u001b[39m=\u001b[39m Chroma\u001b[39m.\u001b[39mfrom_documents(texts, embeddings)\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.11/site-packages/langchain/vectorstores/chroma.py:412\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m texts \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    411\u001b[0m metadatas \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[0;32m--> 412\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mfrom_texts(\n\u001b[1;32m    413\u001b[0m     texts\u001b[39m=\u001b[39mtexts,\n\u001b[1;32m    414\u001b[0m     embedding\u001b[39m=\u001b[39membedding,\n\u001b[1;32m    415\u001b[0m     metadatas\u001b[39m=\u001b[39mmetadatas,\n\u001b[1;32m    416\u001b[0m     ids\u001b[39m=\u001b[39mids,\n\u001b[1;32m    417\u001b[0m     collection_name\u001b[39m=\u001b[39mcollection_name,\n\u001b[1;32m    418\u001b[0m     persist_directory\u001b[39m=\u001b[39mpersist_directory,\n\u001b[1;32m    419\u001b[0m     client_settings\u001b[39m=\u001b[39mclient_settings,\n\u001b[1;32m    420\u001b[0m     client\u001b[39m=\u001b[39mclient,\n\u001b[1;32m    421\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.11/site-packages/langchain/vectorstores/chroma.py:373\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    344\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_texts\u001b[39m(\n\u001b[1;32m    345\u001b[0m     \u001b[39mcls\u001b[39m: Type[Chroma],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    355\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Chroma:\n\u001b[1;32m    356\u001b[0m     \u001b[39m\"\"\"Create a Chroma vectorstore from a raw documents.\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \n\u001b[1;32m    358\u001b[0m \u001b[39m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[39m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 373\u001b[0m     chroma_collection \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\n\u001b[1;32m    374\u001b[0m         collection_name\u001b[39m=\u001b[39mcollection_name,\n\u001b[1;32m    375\u001b[0m         embedding_function\u001b[39m=\u001b[39membedding,\n\u001b[1;32m    376\u001b[0m         persist_directory\u001b[39m=\u001b[39mpersist_directory,\n\u001b[1;32m    377\u001b[0m         client_settings\u001b[39m=\u001b[39mclient_settings,\n\u001b[1;32m    378\u001b[0m         client\u001b[39m=\u001b[39mclient,\n\u001b[1;32m    379\u001b[0m     )\n\u001b[1;32m    380\u001b[0m     chroma_collection\u001b[39m.\u001b[39madd_texts(texts\u001b[39m=\u001b[39mtexts, metadatas\u001b[39m=\u001b[39mmetadatas, ids\u001b[39m=\u001b[39mids)\n\u001b[1;32m    381\u001b[0m     \u001b[39mreturn\u001b[39;00m chroma_collection\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.11/site-packages/langchain/vectorstores/chroma.py:71\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     72\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCould not import chromadb python package. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease install it with `pip install chromadb`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m     )\n\u001b[1;32m     76\u001b[0m \u001b[39mif\u001b[39;00m client \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client \u001b[39m=\u001b[39m client\n",
      "\u001b[0;31mValueError\u001b[0m: Could not import chromadb python package. Please install it with `pip install chromadb`."
     ]
    }
   ],
   "source": [
    "docsearch = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(model_name=\"gpt-4\",streaming=True), chain_type=\"stuff\", retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The design principles of biochemical oscillators can be summarized as follows:\\n\\n1. Negative feedback: This is necessary to bring the reaction network back to the starting point of its oscillation. The negative feedback signal ensures that if a concentration of a component gets too large, it will eventually decrease, and if it gets too small, it will eventually increase.\\n\\n2. Time delay: The negative feedback signal must be sufficiently delayed in time so that the chemical reactions do not home in on a stable steady state. Time-delay can be created by a physical constraint, a long chain of reaction intermediates, or by dynamical hysteresis (overshoot and undershoot) as consequences of positive feedback in the reaction mechanism.\\n\\n3. Nonlinearity: The kinetic rate laws of the reaction mechanism must be sufficiently nonlinear to destabilize the steady state. In biochemical reaction kinetics, there are many sources of nonlinearity that are conducive to oscillations.\\n\\n4. Proper balancing of time scales: The reactions that produce and consume the interacting chemical species must occur on appropriate time scales that permit the network to generate oscillations. This balance ensures that the system can maintain its oscillatory behavior.\\n\\nThese design principles are derived from studying specific examples of oscillatory processes and help in understanding the mechanisms underlying cellular oscillations.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are the design principles of biochemical oscillators?\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, PromptTemplate, LLMChain\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
